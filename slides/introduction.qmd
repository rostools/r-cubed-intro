---
format: rostools-theme-revealjs
---

# Welcome to the Introductory R^3^ workshop!

-   :heavy_check_mark: Pick a group name from the basket and go to that
    table
-   :heavy_check_mark: Introduce yourself to your group members
-   :heavy_check_mark: Accept the GitHub Organization invite

::: notes
Introduce instructors and helpers after welcoming everyone and getting
them to do this.
:::

## :raising_hand_woman: Before this workshop... How many knew or have heard about <u>reproducibility</u>? {.center}

::: notes
Raise your hands.
:::

## :raising_hand_woman: Before this workshop... How many knew or have heard about <u>open science</u>? {.center}

## :raising_hand_man: Before this workshop... or even <u>open access, open data, open methods/protocols, or open source</u>? {.center}

## :raising_hand_woman: How many have read a method in a paper and wondered how they <u>actually</u> did it? {.center}

::: notes
Because you are trying to do the same or similar?

And you've probably realize by now, way more is done than shown in the
"Methods".
:::

## :raising_hand_man: Have you ever received confusing code? Or maybe have written your own confusing code? {.center}

::: notes
For those that have worked with code.

I definitely have in my research career. We want to change the culture
around code by encouraging and teaching how to share code and to write
better code in general.
:::

# These highlight a problem in science... {.center}

## The scientific principle of "reproducibility" and code sharing {.smaller}

... often confused with "replicability" [@Plesser2018a]
[^introduction-1]

[^introduction-1]: Also from [American Statistical
    Association](https://www.amstat.org/asa/files/pdfs/POL-ReproducibleResearchRecommendations.pdf).

::: notes
How many could tell me the difference between replicable and
reproducible?
:::

. . .

::::: columns
::: {.column width="50%"}
### Replicability

-   Same analysis + same methods + new data = same result?
-   *Independently* conducted study
-   Difficult, usually needs funding
-   Linked to the "irreproducibility crisis"[^introduction-2]
:::

::: {.column width="50%"}
### Reproducibility

-   Same data + same code = same result?
-   Should be easy right? Wrong, often just as hard
-   *Question*: If we can't even *reproduce* a studies results, how can
    we expect to replicate it?
:::
:::::

[^introduction-2]: Or rather "irreplicability crisis".

## Biomedical studies almost entirely don't publish code with the published paper {.center}

See: [@Leek2017a; @Considine2017a; @Seibold2021]

::: notes
Vast majority of papers *still* don't provide code. Except for maybe in
bioinformatics, where a bit more than half of studies do. There are lots
of reasons for this, that I talk more about tomorrow.

And this is no joke. Getting data on this is difficult, but the research
that has been done shows that almost no one is sharing their code. The
estimates range between fields in health science from zero to maybe five
percent of published studies. The only area that is doing pretty well is
bioinformatics, at about 60% of published studies.
:::

## How can we check reproducibility if no code is given? {.center}

This is a little bit of a rhetorical question
:stuck_out_tongue_closed_eyes:

## Very low reproducibility in most of science [@Samuel2024] {.smaller}

::: {layout-ncol="2"}
```{r}
#| echo: false
#| fig-height: 6
library(tidyverse)
theme_set(
  theme_minimal() +
    theme(
      plot.background = element_rect(fill = "#E9E9E9"),
      axis.title = element_blank(),
      axis.text.y = element_text(size = 18),
      axis.text.x = element_blank(),
      axis.ticks = element_blank(),
      axis.line = element_blank()
    )
)

search <- tribble(
  ~item, ~description, ~value, ~order,
  "Articles", "Found among all articles", 3467, 1,
  "GitHub\nrepos", "Those with a GitHub link and at least one notebook", 2660, 2
) |>
  mutate(
    item = fct_rev(fct_reorder(item, order))
  )

ggplot(search, aes(y = item, x = value, label = value)) +
  geom_col(fill = "#203C6E") +
  geom_text(nudge_x = 200, size = 5.5)
```

```{r}
#| echo: false
#| fig-height: 6
repro_results <- tribble(
  ~item, ~description, ~value, ~order,
  "Total notebooks", "Total notebook files found in all the repositories", 27271, 1,
  "Notebook repo\nwas valid", "File names were correct, dependency information was available, no local modules were needed.", 15817, 2,
  "Could install\ndependencies", "Could install dependencies without errors.", 10388, 3,
  "Finished executing\nwithout errors", "Could run without any errors.", 1203, 4,
  "Same results\nas paper", "When the results of the paper matched what the execution results output.", 879, 5
) |>
  mutate(
    percent = str_c(value, "\n(", round(value / max(value) * 100), "%)"),
    item = fct_rev(fct_reorder(item, order))
  )

ggplot(repro_results, aes(y = item, x = value, label = percent)) +
  geom_col(fill = "#203C6E") +
  geom_text(nudge_x = 1700, size = 5.5)
```
:::

## Even in institutional code and data archive, *executability* is low! [@Trisovic2022] {.center}

-   Code taken from [Harvard Dataverse Project](https://dataverse.org/)
    data repositories
-   Only 25% could be *executed* without some "cleaning up"
-   After some automatic cleaning, \~50% could *execute*

::: notes
Recent large study on general reproducibility of projects that shared
code.

Initially only 25% of the R scripts could be *executed* (doesn't mean
results were reproduced though). After doing automatic and some manual
code cleaning, than about half could be executed. That's not bad.

Since scripts were taken from Dataverse.org, researchers who upload
their code and projects to it probably are a bit more aware and
knowledgeable about general reproducibility and coding then the average
researcher, so the results are a bit biased.
:::

## Scientific culture is not well-prepared for analytic and computation era {.center}

## These issues can be fixed by creating and nurturing a culture of openness {.center}

::: notes
All of this is because of a problem with our culture in research. We
aren't open, we don't really share, and don't often follow basic
principles of science. To fix this, we need to start creating and
nurturing a better and healthier culture. We all can be involved in
that, we all have that power to do something, even if its small thing.
:::

## Goal of this workshop: Start changing the culture by providing the training {.center}

# workshop details

## Setup and layout {.smaller}

::::: columns
::: column
-   The workshop is mix of:
    -   "Code-alongs" (we type and explain, you type along)
    -   Hands-on coding, discussing, and reading exercises
    -   Group project (quickly go over it and the GitHub page)
-   All material is online (and [openly
    licensed](https://r-cubed-intro.rostools.org/LICENSE.html))
-   [Resources Appendix](https://guides.rostools.org/learning.html)
    -   Material for further learning
:::

::: column
-   Coding is just as much social as it is solo
    -   Every morning, draw a table names from the bowl and sit at that
        table
    -   Introduce yourself to your table mates
    -   During lunch, sit beside someone you don't know
    -   Several networking activities after most lunch
:::
:::::

::: notes
Explain a bit more about the reading, why doing it, and that this workshop
in particular has a lot more of it than more advanced workshops.

With the final group project, you'll be in the same group for the
workshop, working together on it and on the final exercises. As a team,
you'll help each other out with learning and overcoming any struggles,
with of workshop our help too!

I've tried to organize the groups to include a range of skills and
experiences, so there is a mix of novice and more experienced users.
:::

## Getting or asking for help :raising_hand_woman::raising_hand_man:

::::: columns
::: column
-   Put the sticky/origami hats :tophat: on your laptop to get help
-   There are lots of helpers
-   Table mates, try to help out too
-   For some, the pace may feel too slow. For others, too fast. We want
    fewer people to say it was too fast.
:::

::: column
-   We're all learning here!
-   This is a supportive and safe environment
-   Remember our [Code of Conduct](conduct.html)
:::
:::::

::: notes
We always get feedback that for some it is too fast and for others it is
too slow, especially during this introductory workshop. Ideally, everyone
would say it was the perfect speed. But that is impossible to achieve.
So instead, we aim as much as possible to have fewer people say it was
too fast than people who say it was too slow. This is an introduction
workshop, so we're trying to assume as little to no knowledge on many of
these concepts. So, for those with some knowledge, it *will* feel slow
at times! You can always help your neighbour out to help pass the time
:::

## Practice using stickies: Have you joined the GitHub Organization? {.center}

# Activities {.center}

## :walking_man::walking_woman: Who has used any other coding tool (like Stata)? {.center}

## :walking_man::walking_woman: Those who have used other coding tools, have you had formal training in "coding" in it? {.center}

## :walking_man::walking_woman: How do you perceive your general skill in data analysis? {.center}

## :walking_man::walking_woman: How nervous are you about learning R? {.center}

## :walking_man::walking_woman: Who has not yet used R? {.center}

::: notes
Go to different sides of the room for "Yes" and "No"
:::

## :walking_woman::walking: Those who've used R, how do you perceive your skill in R? {.center}

::: notes
Arrange along the wall from beginner to advanced.
:::

## :chair: Ok, get back into your chairs {.center}

# References
